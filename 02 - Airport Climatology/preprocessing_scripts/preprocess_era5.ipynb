{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaination\n",
    "The following script processes a single 6GB netcdf file into a more managable 1MB file for analysis.\n",
    "\n",
    "## About the data\n",
    "This ERA5 dataset contains 10 years of convective rain rate and convective avalaible potential energy at a 31 km spatial resolution over Australia.\n",
    "\n",
    "## About the tools\n",
    "As you'll see, xarray is a powerful tool for manipulating netcdf datasets without reading the entire dataset into memory.\n",
    "Here xarray is used to find the nearest ERA5 grid point to each airport location.\n",
    "\n",
    "__You can't need to run this script as the data file isn't hosted on this server__ If you want to run this script, let me know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the python libraries we'll need and define a function that uses pandas to read out airport catalogue\n",
    "\n",
    "import xarray as xr #used for manipulating netcdf datasets\n",
    "import numpy as np #used for arrays\n",
    "import pandas #used in our case for reading csv files\n",
    "\n",
    "def read_csv(csv_ffn, header_line):\n",
    "    \"\"\"\n",
    "    CSV reader used for the radar locations file (comma delimited)\n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "        csv_ffn: str\n",
    "            Full filename to csv file\n",
    "            \n",
    "        header_line: int or None\n",
    "            to use first line of csv as header = 0, use None to use column index\n",
    "            \n",
    "    Returns:\n",
    "    ========\n",
    "        as_dict: dict\n",
    "            csv columns are dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pandas.read_csv(csv_ffn, header=header_line, skipinitialspace=True)\n",
    "    as_dict = df.to_dict(orient='list')\n",
    "    return as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the location of our datasets\n",
    "airport_csv_fn = 'airport_table.csv'\n",
    "era5_ffn = '/g/data/kl02/jss548/era5-data/cape_convrain_sfc_era5.nc'\n",
    "out_folder = '../preprocessed_data/'\n",
    "\n",
    "#define dates\n",
    "start_date = '20090101'\n",
    "end_date = '20181231'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load airport list\n",
    "ap_dict = read_csv(airport_csv_fn, header_line=1)\n",
    "ap_name_list = ap_dict['Name']\n",
    "ap_lat_list = ap_dict['Latitude']\n",
    "ap_lon_list = ap_dict['Longitude']\n",
    "ap_rid_list = ap_dict['radar_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished MEL\n",
      "finished SYD\n",
      "finished WSYD\n",
      "finished BNE\n"
     ]
    }
   ],
   "source": [
    "#preprocess ERA5 data\n",
    "\n",
    "#load netcdf data using xarray\n",
    "DS = xr.open_dataset(era5_ffn)\n",
    "\n",
    "#loop through each airport\n",
    "for i, ap_name in enumerate(ap_name_list):\n",
    "    \n",
    "    #for each variable, use the xarray 'sel' function to filter data by nearest grid point to the airport location, and the time range\n",
    "    era5_cape = DS.cape.sel(longitude=ap_lon_list[i], method='nearest').sel(latitude=ap_lat_list[i], method='nearest').sel(time=slice(start_date, end_date))\n",
    "    era5_crr = DS.crr.sel(longitude=ap_lon_list[i], method='nearest').sel(latitude=ap_lat_list[i], method='nearest').sel(time=slice(start_date, end_date))\n",
    "    era5_time = DS.time.sel(time=slice(start_date, end_date))\n",
    "    \n",
    "    #save to file using numpyz format\n",
    "    save_path = out_folder + ap_name + '_era5.npz'\n",
    "    np.savez(save_path, era5_cape=era5_cape[:], era5_crr=era5_crr[:], era5_time=era5_time[:])\n",
    "    \n",
    "    print('finished', ap_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__By extracted exactly what we need for analysis, we've converted a 6.3 GB dataset into 4 x 0.5 MB files.__\n",
    "\n",
    "This will save us lots of time when analysing the data later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
